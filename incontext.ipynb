{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "#     doc = fitz.open(pdf_path)\n",
    "#     text = \"\"\n",
    "#     for page_num in range(len(doc)):\n",
    "#         page = doc.load_page(page_num)\n",
    "#         text += page.get_text()\n",
    "#     return text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file with pypdf2.\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "# Example usage:\n",
    "pdf_folder = 'data/'\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "\n",
    "# create a dictionary to store the text of each pdf and the metadata and if there is a txt with the same name\n",
    "contex = {}\n",
    "for pdf_file in pdf_files:\n",
    "    contex[pdf_file]={}\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    contex[pdf_file]['pdf'] = text\n",
    "    # get the metadata\n",
    "    #metadata = fitz.open(pdf_path).metadata\n",
    "    metadata = PdfReader(pdf_path).metadata\n",
    "    contex[pdf_file]['metadata'] = metadata\n",
    "    # check if there is a txt with the same name\n",
    "    txt_path = os.path.join(pdf_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, 'r') as file:\n",
    "            contex[pdf_file]['transcript'] = file.read()\n",
    "\n",
    "    else:\n",
    "        contex[pdf_file]['transcript'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'gibsons',\n",
       " 'location type': 'municipality',\n",
       " 'meeting type': 'regular_council',\n",
       " 'data type': 'minutes',\n",
       " 'meeting date': Timestamp('2024-04-09 00:00:00'),\n",
       " 'transcript': 'Yes',\n",
       " 'comment': nan}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one file:\n",
    "pdf_folder = 'data/batch/'\n",
    "metting_name = \"gib_mcp_rgc_min__2024-04-09__01\"\n",
    "# read the info from a xlsx file\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"data/meetingmap.xlsx\")\n",
    "df = df.set_index('standard name')\n",
    "# get the info of the meeting\n",
    "meeting_info = df.loc[metting_name+\".pdf\"]\n",
    "# return all the columns for the meeting\n",
    "meeting_info = meeting_info.to_dict()\n",
    "meeting_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "pdf_files = [metting_name+\".pdf\"]\n",
    "\n",
    "# create a dictionary to store the text of each pdf and the metadata and if there is a txt with the same name\n",
    "contex = {}\n",
    "for pdf_file in pdf_files:\n",
    "    contex[pdf_file]={}\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    contex[pdf_file]['pdf'] = text\n",
    "    # get the metadata\n",
    "    metadata = fitz.open(pdf_path).metadata\n",
    "    contex[pdf_file]['metadata'] = metadata\n",
    "    # check if there is a txt with the same name\n",
    "    txt_path = os.path.join(pdf_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, 'r') as file:\n",
    "            contex[pdf_file]['transcript'] = file.read()\n",
    "\n",
    "    else:\n",
    "        contex[pdf_file]['transcript'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdf', 'metadata', 'transcript'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex[pdf_files[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=512, overlap=256):\n",
    "    \"\"\"Divides text into overlapping chunks.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        chunk.append(sentence)\n",
    "        current_length += len(sentence.split())\n",
    "\n",
    "        if current_length >= chunk_size:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = chunk[-(overlap // len(sentence.split())):]  # Start next chunk with the overlap\n",
    "            current_length = len(\" \".join(chunk).split())\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage:\n",
    "input_text = [contex[pdf_file]['pdf'] for pdf_file in pdf_files]\n",
    "for text in input_text:\n",
    "    chunks = chunk_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better option\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1024, chunk_overlap=50\n",
    ")\n",
    "input_txt = [contex[pdf_file]['pdf'] for pdf_file in pdf_files]\n",
    "for text in input_text:\n",
    "    all_splits = text_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "# gpt4all_kwargs = {'allow_download': 'True'}\n",
    "\n",
    "# embedding = GPT4AllEmbeddings(  model_name=model_name,\n",
    "#     gpt4all_kwargs=gpt4all_kwargs)\n",
    "# # Index\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=all_splits,\n",
    "#     collection_name=\"rag-chroma\",\n",
    "#     embedding=embedding,\n",
    "# )\n",
    "# retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 2 ...\n",
      "2  new proposals was found in this chunk\n",
      "Processing chunk 2 of 2 ...\n",
      "3  new proposals was found in this chunk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Ollama(model=\"phi3\")\n",
    "\n",
    "PROMPT =\"\"\"<|system|>\n",
    "You are an expert in finding proposals in a meeting note. You are provided with a context delimited by ### which is a chunk of a large meeting note. The goal is to find unique individual proposals in the meeting. Your task is to find the count of new proposal and write the title of the proposal(s). Seperate different proposals by  ||. You also will be given the title from the previous proposal, Do NOT count it as a new one if it was in the previous chunk. If a proposal is not complete (does not have the result), do not count it. Do NOT write more than 10 words for each proposal.  Your output style should be this: \"<num proposal> || <proposal title> || <proposal title> ...\". Here are two examples:\n",
    "example 1 \n",
    "Context:###Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT\\n MOVED by Councillor Carr ###\n",
    "ast proposal: ###  the Minutes of the Council meeting of February 6, 2024, be approved. ###\n",
    "assistant: 2 || the Minutes of the Council meeting following the Standing Committee on City Finance and Services, be approved || the Minutes of the Court of Revision (Business Improvement Areas) meeting of February 8, 2024, be approved.\n",
    "\n",
    "example 2 \n",
    "Context: ###  Tax Rates Bylaw”:\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be considered.\\n CARRIED UNANIMOUSLY \\n R2024-04-22/10\\n BYLAW FIRST, SECOND AND THIRD READINGS \\n 11. “Tax Rates Bylaw, 2024, No. 9017” \\n Moved by Councillor Valente, seconded by Councillor Shahriari\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be given first and second readings;\\n AND THAT “Tax Rates Bylaw, 2024, No. 9017” be given third reading.\\n CARRIED UNANIMOUSLY\\n R2024-04-22/11\\n PUBLIC CLARIFICATION PERIOD\\n Mayor Buchanan declared a recess at 9:44 pm for the Public Clarification Period and  \\n Report: Manager, Public Realm Infrastructure, April 10, 2024\\n Moved by Councillor Valente, seconded by Councillor Girard AND THAT staff be directed of the\\n Lonsdale Highway Overpass Mobility Improvements with the Phase 1 concept of the\\n Upper Levels Greenway to develop a coordinated  \\n Business Licensing ###\n",
    "last proposal: ### Tax Rates Bylaw, 2024, No. 9017” be considered.###\n",
    "assistant: 1 || Tax Rates Bylaw, 2024, No. 9017” be given first and second readings\n",
    "<|end|>\n",
    "<|user|>\n",
    "Context:\n",
    "###\n",
    "{context}\n",
    "###\n",
    "\n",
    "Last proposal:\n",
    "###\n",
    "{latest_proposal}\n",
    "###\n",
    "<|end|>\n",
    "<|assistant|> \"\"\" \n",
    "\n",
    "PROMPT =\"\"\"<|system|>\n",
    "You are an expert in finding proposals in a meeting note. You are provided with a context delimited by ### which is a chunk of a large meeting note. The goal is to find unique individual proposals in the meeting. Your task is to find the count of new proposal and write the title of the proposal(s). Seperate different proposals by  ||. You also will be given the title from the previous proposal, Do NOT count it as a new one if it was in the previous chunk. If a proposal is not complete (does not have the result), do not count it. Do NOT write more than 10 words for each proposal.  Your output style should be this: \"<num proposal> || <proposal title> || <proposal title> ...\". Here is an example: \n",
    "Context:###Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT\\n MOVED by Councillor Carr ###\n",
    "ast proposal: ###  the Minutes of the Council meeting of February 6, 2024, be approved. ###\n",
    "assistant: 2 || the Minutes of the Council meeting following the Standing Committee on City Finance and Services, be approved || the Minutes of the Court of Revision (Business Improvement Areas) meeting of February 8, 2024, be approved.\n",
    "<|end|>\n",
    "<|user|>\n",
    "Context:\n",
    "###\n",
    "{context}\n",
    "###\n",
    "\n",
    "Last proposal:\n",
    "###\n",
    "{latest_proposal}\n",
    "###\n",
    "<|end|>\n",
    "<|assistant|> \"\"\" \n",
    "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "\n",
    "chain = prompt | model\n",
    "latest_proposal = \"\"\n",
    "proposal_dictionary = {}\n",
    "total_chunks = len(all_splits)\n",
    "iterator = 1\n",
    "while iterator <= total_chunks:\n",
    "    context = all_splits[iterator-1]\n",
    "    print(f'Processing chunk {iterator} of {total_chunks} ...')\n",
    "    latest_proposal = chain.invoke({'context': context, 'latest_proposal':latest_proposal})\n",
    "    # parse the latest_proposal and seperate them if it has special token <sep>\n",
    "    latest_proposal = latest_proposal.split('||') \n",
    "    if len(latest_proposal) == 0:\n",
    "        print(f\"There was an error in chunk {iterator}, no || found, running again\")\n",
    "        continue\n",
    "    try:\n",
    "        int(latest_proposal[0])\n",
    "    except:\n",
    "        print(f\"There was an error in chunk {iterator}, running again\")\n",
    "        continue\n",
    "    print(f\"{latest_proposal[0]} new proposals was found in this chunk\")\n",
    "    proposal_dictionary[iterator-1] = latest_proposal[1:]\n",
    "    latest_proposal = latest_proposal[-1]\n",
    "    iterator += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Development Permit Delegation Authority Amendment Bylaw No.1054-04, 2024 be adopted. ',\n",
       " ' 2024 Annual Tax Rates Bylaw and the 2024-2028 Financial Plan Bylaw be prepared for Council approval.',\n",
       " ' Parcel Tax Roll Review Panel at Town’s Council chambers; Council members appointed to the panel ',\n",
       " ' Support Sunshine Coast Regional District applying for CEPF Evacuation Route Planning grant funding on behalf of Town of Gibsons. ',\n",
       " ' Reinstates Canada Day celebrations as prior to COVID and approves Oceanfest event funding by $5,000.\\n\\nsupport: Community Emergency Preparedness Fund (CEPF) Evacuation Route Planning grant funding for Sunshine Coast Regional District on behalf of the Town of Gibsons ',\n",
       " ' Reinstates Canada Day celebrations as prior to COVID and approves Oceanfest event funding by $5,000. ',\n",
       " ' Next Regular meeting date set: Tuesday, April 23, 2 Written in the format: \"<num proposal> ',\n",
       " ' <proposal title> ',\n",
       " ' <proposal title> ...\", provide a detailed summary of each proposed initiative from the given context. Include information about who moved and seconded it if available. If no additional details are required for proposals, skip those parts but maintain the overall structure.\\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# convert proposal_dictionary to all_proposals list\n",
    "all_proposals = []\n",
    "chunks =[]\n",
    "for  key, value in proposal_dictionary.items():\n",
    "    all_proposals.extend(value)\n",
    "    # populate chunk with the keys on all elements of the value\n",
    "    chunks.extend([key for _ in range(len(value)) ])\n",
    "print(len(all_proposals))\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to figure out if the number of proposal and the splits are not equal what to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the proposal dictionary to a txt file\n",
    "with open('data/proposals_{}.txt'.format(metting_name), 'w') as file:\n",
    "    json.dump(proposal_dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the proposal dictionary from a txt file\n",
    "with open('data/proposals_{}.txt'.format(metting_name), 'r') as file:\n",
    "    proposal_dictionary = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal 2 and 3 are similar with score 0.5201366063344381\n",
      " The North Shore Pickleball Group seeking recognition and a presentation of their vision for a Pickleball hub on the North Shore; Increased need for more pickleball courts, with an example from North Vancouver showing disparity between pickleball and tennis courts; Residents facing parking issues due to no parking restrictions in some areas and inconsistent RPO permit distribution; Confrontations and safety concerns related to traffic and parked vehicles on Rockcliff Road; Concerns about the installation costs and lack of land for new pickleball courts in Lynn Valley.\n",
      " The North Shore Pickleball Group seeking recognition and a presentation of their vision for a Pickleball hub on the North Shore \n",
      "-------------------\n",
      "Proposal 9 and 10 are similar with score 0.972305585328247\n",
      " Pickleball Courts Expansion: Identify potential sites for new courts or expansion of existing ones in the District of North Vancouver; address resident exemptions and parking at 2151 Banbury Place as part of Deep Cove Parking Review -2024 Implementation Plan.\n",
      " Identify potential sites for new pickleball courts or expansion of existing ones in the District of North Vancouver; address resident exemptions and parking at 2151 Banbury Place as part of Deep Cove Parking Review -2024 Implementation Plan. \n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# we need to check if the proposals are unique\n",
    "# we can use the cosine similarity to check if the proposals are unique\n",
    "\n",
    "# get the cosine similarity between the proposals\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
    "# select two adjacent proposals and calculate the cosine similarity\n",
    "for i in range(len(all_proposals)-1):\n",
    "    tfidf = vect.fit_transform([all_proposals[i], all_proposals[i+1]])                                                                                                                                                                                                                       \n",
    "    pairwise_similarity = tfidf * tfidf.T \n",
    "    if pairwise_similarity.toarray()[0][1] > 0.5:\n",
    "        print(f\"Proposal {i} and {i+1} are similar with score {pairwise_similarity.toarray()[0][1]}\")\n",
    "        print(all_proposals[i])\n",
    "        print(all_proposals[i+1])  \n",
    "        print('-------------------')                                                                                                                                                                                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the similar proposals\n",
    "to_remove = [3,9]\n",
    "unique_proposals = [all_proposals[i] for i in range(len(all_proposals)) if i not in to_remove]\n",
    "unique_chunks = [chunks[i] for i in range(len(chunks)) if i not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to dictionary\n",
    "unique_proposal_dictionary = {}\n",
    "for i in range(len(unique_chunks)):\n",
    "    if unique_chunks[i] in unique_proposal_dictionary:\n",
    "        unique_proposal_dictionary[unique_chunks[i]].append(unique_proposals[i])\n",
    "    else:\n",
    "        unique_proposal_dictionary[unique_chunks[i]] = [unique_proposals[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [' Adoption of the Agenda for April 22, 2024 Regular Meeting | Recognition Awards and Awards of Merit for EBB AND FLOW, including L YNNMOUR APARTMENTS and various architectural firms. ',\n",
       "  ' Heritage Advocacy at Capilano Suspension Bridge Park & Grouse Mountain.'],\n",
       " '1': [' The North Shore Pickleball Group seeking recognition and a presentation of their vision for a Pickleball hub on the North Shore; Increased need for more pickleball courts, with an example from North Vancouver showing disparity between pickleball and tennis courts; Residents facing parking issues due to no parking restrictions in some areas and inconsistent RPO permit distribution; Confrontations and safety concerns related to traffic and parked vehicles on Rockcliff Road; Concerns about the installation costs and lack of land for new pickleball courts in Lynn Valley.',\n",
       "  ' Increased need for more pickleball courts, with an example from North Vancouver showing disparity between pickleball and tennis courts ',\n",
       "  ' Residents facing parking issues due to no parking restrictions in some areas and inconsistent RPO permit distribution '],\n",
       " '2': [' Confrontations and safety concerns related to traffic and parked vehicles on Rockcliff Road '],\n",
       " '3': [' Concerns about the installation costs and lack of land for new pickleball courts in Lynn Valley.',\n",
       "  \" Implement engineering solutions to calm traffic in Edgemont Village, instead of a proposed traffic signal at Edgemont and Highland Blvd; report back on funding options for these engineered solutions; evaluate feasibility options for controlling traffic at Frederick Road and Mountain Highway; utilize DNV's 2014 Edgemont plan and design guidelines to enhance safety, pedestrian friendlinayer and beauty in Edgemont Village. \"],\n",
       " '4': [' Identify potential sites for new pickleball courts or expansion of existing ones in the District of North Vancouver; address resident exemptions and parking at 2151 Banbury Place as part of Deep Cove Parking Review -2024 Implementation Plan. ',\n",
       "  \" Approve on-street public parking management strategy in Deep Cove, including resident and time-limited parking, with options for Deep Cove business employees to certain parking restrictions before March 31, 2025; further investigation of exempting employees' parking options. \",\n",
       "  ' Council approve the implementation plan described in April 1, 2024 report for on-street public parking management strategy in Deep Cove.']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_proposal_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 || Tax Rates Bylaw, 2024, No. 9017\" be given first and second readings ###\n",
      "Example 2 assistant: 1 || Tax Rates Bylaw, 2024, No. 9017\" be considered."
     ]
    }
   ],
   "source": [
    "#test\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = Ollama(model=\"phi3\")\n",
    "\n",
    "PROMPT =\"\"\"<|system|>\n",
    "You are an expert in finding proposals in a meeting note. You are provided with a context delimited by ### which is a chunk of a large meeting note. The goal is to find unique individual proposals in the meeting. Your task is to find the count of new proposal and write the title of the proposal(s). Seperate different proposals by  ||. You also will be given the title from the previous proposal, Do NOT count it as a new one if it was in the previous chunk. If a proposal is not complete (does not have the result), do not count it. Your output style should be this: \"<num proposal> || <proposal title> || <proposal title> ...\". Here are two examples:\n",
    "example 1 \n",
    "Context:###Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT\\n MOVED by Councillor Carr ###\n",
    "ast proposal: ###  the Minutes of the Council meeting of February 6, 2024, be approved. ###\n",
    "assistant: 2 || the Minutes of the Council meeting following the Standing Committee on City Finance and Services, be approved || the Minutes of the Court of Revision (Business Improvement Areas) meeting of February 8, 2024, be approved.\n",
    "\n",
    "example 2 \n",
    "Context: ###  Tax Rates Bylaw”:\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be considered.\\n CARRIED UNANIMOUSLY \\n R2024-04-22/10\\n BYLAW FIRST, SECOND AND THIRD READINGS \\n 11. “Tax Rates Bylaw, 2024, No. 9017” \\n Moved by Councillor Valente, seconded by Councillor Shahriari\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be given first and second readings;\\n AND THAT “Tax Rates Bylaw, 2024, No. 9017” be given third reading.\\n CARRIED UNANIMOUSLY\\n R2024-04-22/11\\n PUBLIC CLARIFICATION PERIOD\\n Mayor Buchanan declared a recess at 9:44 pm for the Public Clarification Period and  \\n Report: Manager, Public Realm Infrastructure, April 10, 2024\\n Moved by Councillor Valente, seconded by Councillor Girard AND THAT staff be directed of the\\n Lonsdale Highway Overpass Mobility Improvements with the Phase 1 concept of the\\n Upper Levels Greenway to develop a coordinated  \\n Business Licensing ###\n",
    "last proposal: ### Tax Rates Bylaw, 2024, No. 9017” be considered.###\n",
    "assistant: 1 || Tax Rates Bylaw, 2024, No. 9017” be given first and second readings\n",
    "<|end|>\n",
    "<|user|>\n",
    "Context:\n",
    "###\n",
    "{context}\n",
    "###\n",
    "\n",
    "Last proposal:\n",
    "###\n",
    "{latest_proposal}\n",
    "###\n",
    "<|end|>\n",
    "<|assistant|> \"\"\" \n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({'context': all_splits[0], 'latest_proposal':latest_proposal}):\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "local_llm = \"phi3\"\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Schema for structured response\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"The person's name\", required=True)\n",
    "    height: float = Field(description=\"The person's height\", required=True)\n",
    "    hair_color: str = Field(description=\"The person's hair color\")\n",
    "\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Alex is 5 feet tall. \n",
    "Claudia is 1 feet taller than Alex and jumps higher than him. \n",
    "Claudia is a brunette and Alex is blonde.\n",
    "\n",
    "Human: {question}\n",
    "AI: \"\"\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Person)\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "alex = chain.invoke(\"Describe Alex\")\n",
    "alex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
