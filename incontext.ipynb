{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "#     doc = fitz.open(pdf_path)\n",
    "#     text = \"\"\n",
    "#     for page_num in range(len(doc)):\n",
    "#         page = doc.load_page(page_num)\n",
    "#         text += page.get_text()\n",
    "#     return text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file with pypdf2.\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "# Example usage:\n",
    "pdf_folder = 'data/'\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "\n",
    "# create a dictionary to store the text of each pdf and the metadata and if there is a txt with the same name\n",
    "contex = {}\n",
    "for pdf_file in pdf_files:\n",
    "    contex[pdf_file]={}\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    contex[pdf_file]['pdf'] = text\n",
    "    # get the metadata\n",
    "    #metadata = fitz.open(pdf_path).metadata\n",
    "    metadata = PdfReader(pdf_path).metadata\n",
    "    contex[pdf_file]['metadata'] = metadata\n",
    "    # check if there is a txt with the same name\n",
    "    txt_path = os.path.join(pdf_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, 'r') as file:\n",
    "            contex[pdf_file]['transcript'] = file.read()\n",
    "\n",
    "    else:\n",
    "        contex[pdf_file]['transcript'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'gibsons',\n",
       " 'location type': 'municipality',\n",
       " 'meeting type': 'regular_council',\n",
       " 'data type': 'minutes',\n",
       " 'meeting date': Timestamp('2024-04-09 00:00:00'),\n",
       " 'transcript': 'Yes',\n",
       " 'comment': nan}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one file:\n",
    "pdf_folder = 'data/batch/'\n",
    "metting_name = \"gib_mcp_rgc_min__2024-04-09__01\"\n",
    "# read the info from a xlsx file\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"data/meetingmap.xlsx\")\n",
    "df = df.set_index('standard name')\n",
    "# get the info of the meeting\n",
    "meeting_info = df.loc[metting_name+\".pdf\"]\n",
    "# return all the columns for the meeting\n",
    "meeting_info = meeting_info.to_dict()\n",
    "meeting_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "pdf_files = [metting_name+\".pdf\"]\n",
    "\n",
    "# create a dictionary to store the text of each pdf and the metadata and if there is a txt with the same name\n",
    "contex = {}\n",
    "for pdf_file in pdf_files:\n",
    "    contex[pdf_file]={}\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    contex[pdf_file]['pdf'] = text\n",
    "    # get the metadata\n",
    "    metadata = fitz.open(pdf_path).metadata\n",
    "    contex[pdf_file]['metadata'] = metadata\n",
    "    # check if there is a txt with the same name\n",
    "    txt_path = os.path.join(pdf_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, 'r') as file:\n",
    "            contex[pdf_file]['transcript'] = file.read()\n",
    "\n",
    "    else:\n",
    "        contex[pdf_file]['transcript'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdf', 'metadata', 'transcript'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex[pdf_files[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=512, overlap=256):\n",
    "    \"\"\"Divides text into overlapping chunks.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        chunk.append(sentence)\n",
    "        current_length += len(sentence.split())\n",
    "\n",
    "        if current_length >= chunk_size:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "            chunk = chunk[-(overlap // len(sentence.split())):]  # Start next chunk with the overlap\n",
    "            current_length = len(\" \".join(chunk).split())\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage:\n",
    "input_text = [contex[pdf_file]['pdf'] for pdf_file in pdf_files]\n",
    "for text in input_text:\n",
    "    chunks = chunk_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better option\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1024, chunk_overlap=50\n",
    ")\n",
    "input_txt = [contex[pdf_file]['pdf'] for pdf_file in pdf_files]\n",
    "for text in input_text:\n",
    "    all_splits = text_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "# gpt4all_kwargs = {'allow_download': 'True'}\n",
    "\n",
    "# embedding = GPT4AllEmbeddings(  model_name=model_name,\n",
    "#     gpt4all_kwargs=gpt4all_kwargs)\n",
    "# # Index\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=all_splits,\n",
    "#     collection_name=\"rag-chroma\",\n",
    "#     embedding=embedding,\n",
    "# )\n",
    "# retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 2 ...\n",
      " 5  new proposals was found in this chunk\n",
      " Removing proposal (lenght limit) ' '\n",
      "Processing chunk 2 of 2 ...\n",
      " 3  new proposals was found in this chunk\n",
      " Removing proposal (lenght limit) '\n",
      "<|end|>'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Ollama(model=\"llama3\")\n",
    "\n",
    "PROMPT =\"\"\"<|system|>\n",
    "You are an expert in finding proposals in a meeting note. You are provided with a context delimited by ### which is a chunk of a large meeting note. The goal is to find unique individual proposals in the meeting. Your task is to find the count of new proposal and write the title of the proposal(s). Seperate different proposals by  ||. You also will be given the title from the previous proposal, Do NOT count it as a new one if it was in the previous chunk. If a proposal is not complete (does not have the result), do not count it. Do NOT write more than 10 words for each proposal.  Your output style should be this: \"<num proposal> || <proposal title> || <proposal title> ...\". Here are two examples:\n",
    "example 1 \n",
    "Context:###Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT\\n MOVED by Councillor Carr ###\n",
    "ast proposal: ###  the Minutes of the Council meeting of February 6, 2024, be approved. ###\n",
    "assistant: 2 || the Minutes of the Council meeting following the Standing Committee on City Finance and Services, be approved || the Minutes of the Court of Revision (Business Improvement Areas) meeting of February 8, 2024, be approved.\n",
    "\n",
    "example 2 \n",
    "Context: ###  Tax Rates Bylaw”:\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be considered.\\n CARRIED UNANIMOUSLY \\n R2024-04-22/10\\n BYLAW FIRST, SECOND AND THIRD READINGS \\n 11. “Tax Rates Bylaw, 2024, No. 9017” \\n Moved by Councillor Valente, seconded by Councillor Shahriari\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be given first and second readings;\\n AND THAT “Tax Rates Bylaw, 2024, No. 9017” be given third reading.\\n CARRIED UNANIMOUSLY\\n R2024-04-22/11\\n PUBLIC CLARIFICATION PERIOD\\n Mayor Buchanan declared a recess at 9:44 pm for the Public Clarification Period and  \\n Report: Manager, Public Realm Infrastructure, April 10, 2024\\n Moved by Councillor Valente, seconded by Councillor Girard AND THAT staff be directed of the\\n Lonsdale Highway Overpass Mobility Improvements with the Phase 1 concept of the\\n Upper Levels Greenway to develop a coordinated  \\n Business Licensing ###\n",
    "last proposal: ### Tax Rates Bylaw, 2024, No. 9017” be considered.###\n",
    "assistant: 1 || Tax Rates Bylaw, 2024, No. 9017” be given first and second readings\n",
    "<|end|>\n",
    "<|user|>\n",
    "Context:\n",
    "###\n",
    "{context}\n",
    "###\n",
    "\n",
    "Last proposal:\n",
    "###\n",
    "{latest_proposal}\n",
    "###\n",
    "<|end|>\n",
    "<|assistant|> \"\"\" \n",
    "\n",
    "PROMPT =\"\"\"<|system|>\n",
    "You are an expert in finding proposals in a meeting note. You are provided with a context delimited by ### which is a chunk of a large meeting note. The goal is to find unique individual proposals in the meeting. Your task is to find the count of unique proposal and write the title of the proposal(s). Seperate different proposals by  ||. If a proposal is not complete (does not have the result), do not count it. DO NOT write less than 5 or more than 15 words for each proposal.  \n",
    "\n",
    "Your output style should be this: \"|| <num proposal, n> || <proposal 1 title> || <proposal 2 title> ... || <proposal n title>\". \n",
    "\n",
    "Let's think step by step. Here are the steps to solve the task:\n",
    "1. Find the pattern in the chunk that indicates a proposal.\n",
    "2. Find the number of unique proposals in the chunk. \n",
    "3. Make sure all content about each proposal including the title, proposer, seconder, and the result are included and they are unique.\n",
    "4. Write a title (min 5 to max 15 words) for those proposals delimited by ||.\n",
    "\n",
    "Here is an example: \n",
    "Context: ###Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT\\n MOVED by Councillor Carr \\n Tax Rates Bylaw”:\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be considered.\\n R2024-04-22/10\\n BYLAW FIRST,   ###\n",
    "thinking steps:\n",
    "1. It is constantly using the word THAT to indicate a proposal.\n",
    "2. found 4 proposals which has THAT\n",
    "3. the last proposal does not have the result, so it is not a complete proposal.\n",
    "4. I have 3 proposals, and will write short title for them.\n",
    "\n",
    "assistant: || 3 ||  the Minutes of the Council meeting of February 6, 2024, be approved. || the Minutes of the Council meeting following the Standing Committee on City Finance and Services, be approved || the Minutes of the Court of Revision (Business Improvement Areas) meeting be approved.\n",
    "<|end|>\n",
    "\n",
    "<|user|>\n",
    "Context:\n",
    "###\n",
    "{context}\n",
    "###\n",
    "<|end|>\n",
    "\n",
    "<|assistant|> \"\"\" \n",
    "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "\n",
    "chain = prompt | model\n",
    "proposal_dictionary = {}\n",
    "proposal_count_dictionary = {}\n",
    "total_chunks = len(all_splits)\n",
    "iterator = 1\n",
    "while iterator <= total_chunks:\n",
    "    context = all_splits[iterator-1]\n",
    "    print(f'Processing chunk {iterator} of {total_chunks} ...')\n",
    "    latest_proposal = chain.invoke({'context': context})\n",
    "    # parse the latest_proposal and seperate them if it has special token <sep>\n",
    "    latest_proposal = latest_proposal.split('||') \n",
    "    if len(latest_proposal) == 0:\n",
    "        print(f\"There was an error in chunk {iterator}, no || found, running again\")\n",
    "        continue\n",
    "    try:\n",
    "        int(latest_proposal[1])\n",
    "    except:\n",
    "        print(f\"There was an error in chunk {iterator}, running again\")\n",
    "        print(latest_proposal[1])\n",
    "        continue\n",
    "    print(f\"{latest_proposal[1]} new proposals was found in this chunk\")\n",
    "    proposal_dictionary[iterator-1] = latest_proposal[2:]\n",
    "    # checking for their lenght \n",
    "    for i in reversed(range(len(proposal_dictionary[iterator-1]))):\n",
    "        if len(proposal_dictionary[iterator-1][i]) < 20:\n",
    "            # remove this proposal\n",
    "            print(f\" Removing proposal (lenght limit) '{proposal_dictionary[iterator-1][i]}'\")\n",
    "            proposal_dictionary[iterator-1].pop(i)\n",
    "    proposal_count_dictionary[iterator-1] = int(latest_proposal[1])\n",
    "    if len(proposal_dictionary[iterator-1]) != proposal_count_dictionary[iterator-1]:\n",
    "        print(f\"Warning, proposals in chunk {iterator} does not match the count\")\n",
    "    iterator += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[0, 0, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# convert proposal_dictionary to all_proposals list\n",
    "all_proposals = []\n",
    "chunks =[]\n",
    "for  key, value in proposal_dictionary.items():\n",
    "    all_proposals.extend(value)\n",
    "    # populate chunk with the keys on all elements of the value\n",
    "    chunks.extend([key for _ in range(len(value)) ])\n",
    "print(len(all_proposals))\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the count for each proposal in the chunks\n",
    "# count the number of elements in the chunks\n",
    "proposal_count_returned = {i:chunks.count(i) for i in set(chunks)}\n",
    "# find the chunks that the two dictionaries are different\n",
    "diff = {k: proposal_count_returned[k] - proposal_count_dictionary[k] for k in proposal_count_returned if k in proposal_count_dictionary and proposal_count_returned[k] != proposal_count_dictionary[k]}\n",
    "\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the is differece, we need to look at the proposals that are different\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_similarity_score(proposals):\n",
    "    pairwise_similarity = {}\n",
    "    vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
    "    # select two adjacent proposals and calculate the cosine similarity\n",
    "    for i in range(len(proposals)-1):\n",
    "        tfidf = vect.fit_transform([proposals[i], proposals[i+1]])                                                                                                                                                                                                                       \n",
    "        pairwise_similarity[f'{i}-{i+1}']=(tfidf * tfidf.T).toarray()[0][1]\n",
    "    return pairwise_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in diff.keys():\n",
    "    print(f\"Checking the proposals in chunk {k}\")\n",
    "    print(get_similarity_score(proposal_dictionary[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the proposal dictionary to a txt file\n",
    "with open('data/proposals_{}.txt'.format(metting_name), 'w') as file:\n",
    "    json.dump(proposal_dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the proposal dictionary from a txt file\n",
    "with open('data/proposals_{}.txt'.format(metting_name), 'r') as file:\n",
    "    proposal_dictionary = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to check if the proposals are unique\n",
    "# we can use the cosine similarity to check if the proposals are unique\n",
    "\n",
    "# get the cosine similarity between the proposals\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(min_df=1, stop_words=\"english\")\n",
    "to_remove = []\n",
    "# select two adjacent proposals and calculate the cosine similarity\n",
    "for i in range(len(all_proposals)-1):\n",
    "    tfidf = vect.fit_transform([all_proposals[i], all_proposals[i+1]])                                                                                                                                                                                                                       \n",
    "    pairwise_similarity = tfidf * tfidf.T \n",
    "    if pairwise_similarity.toarray()[0][1] > 0.5:\n",
    "        to_remove.append(i+1)\n",
    "        print(f\"Proposal {i} and {i+1} are similar with score {pairwise_similarity.toarray()[0][1]}\")\n",
    "        print(all_proposals[i])\n",
    "        print(all_proposals[i+1])  \n",
    "        print('-------------------')                                                                                                                                                                                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the similar proposals\n",
    "unique_proposals = [all_proposals[i] for i in range(len(all_proposals)) if i not in to_remove]\n",
    "unique_chunks = [chunks[i] for i in range(len(chunks)) if i not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to dictionary\n",
    "unique_proposal_dictionary = {}\n",
    "for i in range(len(unique_chunks)):\n",
    "    if unique_chunks[i] in unique_proposal_dictionary:\n",
    "        unique_proposal_dictionary[unique_chunks[i]].append(unique_proposals[i])\n",
    "    else:\n",
    "        unique_proposal_dictionary[unique_chunks[i]] = [unique_proposals[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [' the minutes of the Regular Council meeting held March 19, 2024 be adopted. ',\n",
       "  ' the Development Permit Delegation Authority Amendment Bylaw No.1054-04, 2024 be adopted. ',\n",
       "  ' the revised preliminary 5-year capital plan for general services be integrated into the 2024-2028 Financial Plan with the exception of the Dog Park and Pickleball projects which are to be removed from the capital plan and referred to the 2025 Parks Master Plan for discussion; AND THAT the proposed budget for the Healthy Harbours Project be approved, with the 2024 portion being funded by accumulated surplus. ',\n",
       "  ' the 2024 annual tax rates be prepared authorizing an overall 8% tax increase (reflecting 3% for general operations and 5% for future policing costs). ',\n",
       "  ' the 2024-2028 Financial Plan Bylaw and the 2024 Annual Tax Rate Bylaw be prepared for Council approval.'],\n",
       " 1: [' Parcel Tax Roll Review Panel – Water/Sewer/Community Recreation be approved ',\n",
       "  ' Canada BC Housing Benefit Program Memorandum of Understanding be executed ',\n",
       "  ' Sunshine Coast Regional District applying for Community Emergency Preparedness Fund (CEPF) grant funding be supported ']}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_proposal_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sectionid</th>\n",
       "      <th>subsectionid</th>\n",
       "      <th>policy_prop</th>\n",
       "      <th>theme</th>\n",
       "      <th>terms</th>\n",
       "      <th>policy_prop_future_date</th>\n",
       "      <th>future_action_date_type</th>\n",
       "      <th>vote_result</th>\n",
       "      <th>theme_as_reviewed</th>\n",
       "      <th>terms_to_remove</th>\n",
       "      <th>terms_to_add</th>\n",
       "      <th>comments</th>\n",
       "      <th>Wrong Cut</th>\n",
       "      <th>future_date_as_reviewed</th>\n",
       "      <th>sentence_suggesting_future_action</th>\n",
       "      <th>voting_result_as_reviewed</th>\n",
       "      <th>Validated?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gib_mcp_rgc_min__2024-04-09__01.pdf</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R2024-66 2024-2028 Preliminary General Service...</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>the Dog\\nPark and Pickleball projects</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CARRIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gib_mcp_rgc_min__2024-04-09__01.pdf</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R2024-69 Parcel Tax Roll Review Panel - Water/...</td>\n",
       "      <td>housing</td>\n",
       "      <td>community</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>exact</td>\n",
       "      <td>CARRIED</td>\n",
       "      <td>drop</td>\n",
       "      <td>community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gib_mcp_rgc_min__2024-04-09__01.pdf</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>R2024-72 Allocation of Community Event Fund:\\n...</td>\n",
       "      <td>housing</td>\n",
       "      <td>community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CARRIED</td>\n",
       "      <td>drop</td>\n",
       "      <td>community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sectionid  subsectionid  \\\n",
       "standard_name                                                  \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf        4.0           1.0   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf        5.0           1.0   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf        6.0           3.0   \n",
       "\n",
       "                                                                           policy_prop  \\\n",
       "standard_name                                                                            \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf  R2024-66 2024-2028 Preliminary General Service...   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf  R2024-69 Parcel Tax Roll Review Panel - Water/...   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf  R2024-72 Allocation of Community Event Fund:\\n...   \n",
       "\n",
       "                                            theme  \\\n",
       "standard_name                                       \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf  unclassified   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf       housing   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf       housing   \n",
       "\n",
       "                                                                     terms  \\\n",
       "standard_name                                                                \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf  the Dog\\nPark and Pickleball projects   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                              community   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                              community   \n",
       "\n",
       "                                    policy_prop_future_date  \\\n",
       "standard_name                                                 \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaN   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf              2024-05-07   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaN   \n",
       "\n",
       "                                    future_action_date_type vote_result  \\\n",
       "standard_name                                                             \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaN     CARRIED   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                   exact     CARRIED   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaN     CARRIED   \n",
       "\n",
       "                                    theme_as_reviewed terms_to_remove  \\\n",
       "standard_name                                                           \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf               NaN             NaN   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf              drop       community   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf              drop       community   \n",
       "\n",
       "                                    terms_to_add comments Wrong Cut  \\\n",
       "standard_name                                                         \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf          NaN      NaN       NaN   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf          NaN      NaN       NaN   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf          NaN      NaN       NaN   \n",
       "\n",
       "                                    future_date_as_reviewed  \\\n",
       "standard_name                                                 \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaT   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaT   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                     NaT   \n",
       "\n",
       "                                    sentence_suggesting_future_action  \\\n",
       "standard_name                                                           \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                               NaN   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                               NaN   \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                               NaN   \n",
       "\n",
       "                                    voting_result_as_reviewed Validated?  \n",
       "standard_name                                                             \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                       NaN        Yes  \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                       NaN        Yes  \n",
       "gib_mcp_rgc_min__2024-04-09__01.pdf                       NaN        Yes  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the information for this specific meeting from the proposals_for_review.xlsx file (training only) sheet review\n",
    "df = pd.read_excel(\"data/proposals_for_review.xlsx\", sheet_name=\"review\")\n",
    "df = df.set_index('standard_name')\n",
    "# get the list of proposals where the meeting name is the same as the current meeting\n",
    "meeting_proposals = df.loc[metting_name+\".pdf\"]\n",
    "\n",
    "meeting_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/proposals_for_review.xlsx\", sheet_name=\"themes\")\n",
    "themes = df['theme'].tolist()\n",
    "themes = ['Uncategorized', 'food', 'housing', 'children', 'climate', 'health', 'environment', 'indigenous', 'women', 'diversity', 'poverty', 'psychoactive', 'mental']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the minutes of the Regular Council meeting held March 19, 2024 be adopted. \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions, convert_to_ollama_tool\n",
    "\n",
    "\n",
    "# Schema for structured response\n",
    "class Proposal(BaseModel):\n",
    "    section: str = Field(description=\"The section and subsection of the proposal\", required=True)\n",
    "    title: str = Field(description=\"A short title of the proposal\", required=True)\n",
    "    policy_prop: str = Field(description=\"Full proposal content\", required=True)\n",
    "    theme: str = Field(description=f\"categorical value from themes: {themes}\", required=True)\n",
    "    vote_result: str = Field(description=\"The result of the vote\", required=True)\n",
    "    future_date: str = Field(description=\"The future date of the proposal\", required=False)\n",
    "\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"<|system|> You are an expert in extracting information related to a proposal from chunk of a text. Your task is to get the proposal from the user and find relevant information only from the given chunk of context delimited by ###. Your answer should follow the following scheme:\n",
    "    section: str = Field(description=\"The section and subsection of the proposal\", required=True)\n",
    "    title: str = Field(description=\"A short title of the proposal\", required=True)\n",
    "    policy_prop: str = Field(description=\"Full proposal content\", required=True)\n",
    "    theme: str = Field(description=\"the most related categorical value from this  list: {themes}\", required=True)\n",
    "    vote_result: str = Field(description=\"The result of the vote\", required=True)\n",
    "    future_date: str = Field(description=\"The future date of the proposal\", required=False)\n",
    "    \n",
    "Let's think step by step. Here are the steps to solve the task:\n",
    "1. Find the given proposal from the user. It is delimted by *** and followed after the PROPOSAL word. \n",
    "2. Locate the given proposal in the context delimited by ###. Try to find where is the beginning and the end of that proposal.\n",
    "3. Look for different required information of that proposal including the section, title, policy_prop, theme, vote_result, and future_date (only if exist).\n",
    "3. Make sure all retrieved information are extracted from the context. If it was not, return all the sections with 'NOT FOUND'.\n",
    "4. Call the tool_calls of langchain_experimental.llms.ollama_functions.OllamaFunctions with the model phi3\n",
    "5. Make sure the return type are correct and in the correct format\n",
    "\n",
    "Here is an example: \n",
    "Context: ###Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT\\n MOVED by Councillor Carr \\n Tax Rates Bylaw”:\\n THAT “Tax Rates Bylaw, 2024, No. 9017” be considered.\\n R2024-04-22/10\\n BYLAW FIRST,   ###\n",
    "PROPOSAL: ***the Minutes of the Council meeting following the Standing Committee on City Finance and Services, be approved ***\n",
    "\n",
    "assistant: \n",
    "thinking steps:\n",
    "1. Found the proposal that is delimited by *** followed by PROPOSAL\n",
    "2. The begining of the proposal is 3. Council (City Finance and Services) and the end is February 7, 2024, be approved. CARRIED UNANIMOUSLY\n",
    "3. section is 3, title is Approve of the Minutes of the Council meeting in Standing Committee on City Finance, policy prop is started after THAT until CARRIED UNANIMOUSLY, theme is Uncategorized, vote result is CARRIED UNANIMOUSLY, future date is February 7, 2024 \n",
    "4. I will call the tool_calls of langchain_experimental.llms.ollama_functions.OllamaFunctions to make sure the structure is correct.\n",
    "5. I double check that the results are valid and in the correct format.\n",
    "\n",
    "tool_calls ...\n",
    "<|end|>\n",
    "\n",
    "<|user|>\n",
    "Context:\n",
    "###\n",
    "{context}\n",
    "###\n",
    "\n",
    "PROPOSAL:\n",
    "###\n",
    "{proposal}\n",
    "###\n",
    "<|end|>\n",
    "\n",
    "<|assistant|> \"\"\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm = OllamaFunctions(model=\"phi3\",format=\"json\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Proposal)\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "iterator = 0\n",
    "context = all_splits[iterator-1]\n",
    "proposal = unique_proposal_dictionary[iterator][0]\n",
    "\n",
    "result = chain.invoke({'themes':themes ,'context': context, 'proposal': proposal})\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
