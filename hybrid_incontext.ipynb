{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'gibsons',\n",
       " 'location type': 'municipality',\n",
       " 'meeting type': 'regular_council',\n",
       " 'data type': 'minutes',\n",
       " 'meeting date': Timestamp('2024-04-09 00:00:00'),\n",
       " 'transcript': 'Yes',\n",
       " 'comment': nan}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one file:\n",
    "pdf_folder = 'data/batch/'\n",
    "metting_name = \"gib_mcp_rgc_min__2024-04-09__01\"\n",
    "pdf_file = metting_name + \".pdf\"\n",
    "pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "# read the info from a xlsx file\n",
    "df = pd.read_excel(\"data/meetingmap.xlsx\")\n",
    "df = df.set_index('standard name')\n",
    "# get the info of the meeting\n",
    "meeting_info = df.loc[pdf_file]\n",
    "# return all the columns for the meeting\n",
    "meeting_info = meeting_info.to_dict()\n",
    "meeting_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# create a dictionary to store the text of each pdf and the metadata and if there is a txt with the same name\n",
    "contex = {}\n",
    "    \n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "contex['pdf'] = text\n",
    "# get the metadata\n",
    "metadata = fitz.open(pdf_path).metadata\n",
    "contex['metadata'] = metadata\n",
    "# check if there is a txt with the same name\n",
    "txt_path = os.path.join(pdf_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "if os.path.exists(txt_path):\n",
    "    with open(txt_path, 'r') as file:\n",
    "        contex['transcript'] = file.read()\n",
    "\n",
    "else:\n",
    "        contex['transcript'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdf', 'metadata', 'transcript'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of themes:  56\n"
     ]
    }
   ],
   "source": [
    "# load the theme keywords from themekeywordmap.xlsx\n",
    "# convert it to a dictionary with the theme as key and different keywords as a list\n",
    "# it has two columns: theme and single phrase\n",
    "# combine all the phrases that have the same theme in  a list as follows\n",
    "# category_keywords = {\n",
    "#     \"theme 1\": [\"phrase 1\", \"phrase 2\", \"phrase 3\"],\n",
    "#     \"theme 2\": [\"phrase 4\", \"phrase 5\", \"phrase 6\", \"phrase 7\"]\n",
    "# }\n",
    "df = pd.read_excel(\"data/themekeywordmap.xlsx\")\n",
    "category_keywords = {}\n",
    "for theme, group in df.groupby('theme'):\n",
    "    category_keywords[theme] = group['phrase'].tolist()\n",
    "print(\"total number of themes: \", len(category_keywords.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Segment using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_patterns = [\n",
    "    r\"MOVED by\",\n",
    "    r\"SECONDED by\",\n",
    "    r\"WHEREAS\",\n",
    "    r\"THEREFORE BE IT RESOLVED THAT\",\n",
    "    r\"CARRIED UNANIMOUSLY\",\n",
    "    r\"REJECTED\",\n",
    "    r\"THAT\",\n",
    "    r\"APPROVED\",\n",
    "    r\"ADOPTED\",\n",
    "    r\"RESOLVED\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_document(document, patterns):\n",
    "    \"\"\"\n",
    "    Segment the document based on defined patterns.\n",
    "    \"\"\"\n",
    "    combined_pattern = '|'.join(patterns)\n",
    "    segments = re.split(combined_pattern, document, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Filter out empty segments and strip whitespace\n",
    "    segments = [seg.strip() for seg in segments if seg.strip()]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keywords(segment, category_keywords):\n",
    "    \"\"\"\n",
    "    Match segments against category keywords.\n",
    "    \"\"\"\n",
    "    matched_categories = []\n",
    "    for category, keywords in category_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', segment, re.IGNORECASE):\n",
    "                matched_categories.append(category)\n",
    "                break  # Break after the first match to avoid redundant checks\n",
    "    return matched_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_segments(segments, category_keywords):\n",
    "    \"\"\"\n",
    "    Combine nearby segments and filter them based on category keywords.\n",
    "    \"\"\"\n",
    "    combined_segments = []\n",
    "    current_segment = \"\"\n",
    "    current_categories = set()\n",
    "\n",
    "    for segment in segments:\n",
    "        matched_categories = match_keywords(segment, category_keywords)\n",
    "        if matched_categories:\n",
    "            if current_segment:\n",
    "                combined_segments.append({\n",
    "                    \"text\": current_segment,\n",
    "                    \"categories\": list(current_categories)\n",
    "                })\n",
    "                current_segment = segment\n",
    "                current_categories = set(matched_categories)\n",
    "            else:\n",
    "                current_segment = segment\n",
    "                current_categories.update(matched_categories)\n",
    "        else:\n",
    "            current_segment += \" \" + segment\n",
    "    \n",
    "    if current_segment:\n",
    "        combined_segments.append({\n",
    "            \"text\": current_segment,\n",
    "            \"categories\": list(current_categories)\n",
    "        })\n",
    "\n",
    "    return combined_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segment_document(contex['pdf'], split_patterns)\n",
    "combined_segments = combine_segments(segments, category_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total initial segments: 8\n"
     ]
    }
   ],
   "source": [
    "# initial assesment results\n",
    "print(\"Total initial segments:\", len(combined_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nlp = json.dumps(combined_segments, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_segments_v2(segments, category_keywords):\n",
    "    \"\"\"\n",
    "    Combine nearby segments and filter them based on category keywords.\n",
    "    \"\"\"\n",
    "    combined_segments = []\n",
    "    current_segment = \"\"\n",
    "    current_categories = set()\n",
    "    last_matched_categories = set()\n",
    "\n",
    "    for segment in segments:\n",
    "        matched_categories = match_keywords(segment, category_keywords)\n",
    "        if matched_categories:\n",
    "            # If current segment is not empty and the new segment has different categories,\n",
    "            # add the current segment to combined_segments and start a new one\n",
    "            if current_segment and matched_categories != last_matched_categories:\n",
    "                combined_segments.append({\n",
    "                    \"text\": current_segment,\n",
    "                    \"categories\": list(current_categories)\n",
    "                })\n",
    "                current_segment = segment\n",
    "                current_categories = set(matched_categories)\n",
    "            else:\n",
    "                current_segment += \" \" + segment\n",
    "                current_categories.update(matched_categories)\n",
    "            last_matched_categories = matched_categories\n",
    "        else:\n",
    "            current_segment += \" \" + segment\n",
    "    \n",
    "    # Append the last segment\n",
    "    if current_segment:\n",
    "        combined_segments.append({\n",
    "            \"text\": current_segment,\n",
    "            \"categories\": list(current_categories)\n",
    "        })\n",
    "\n",
    "    return combined_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_segments = combine_segments_v2(segments, category_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: find category based on vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/pagand/projects/ragprop/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# Generate embeddings for each category based on keywords\n",
    "category_embeddings = {}\n",
    "for category, keywords in category_keywords.items():\n",
    "    category_embeddings[category] = model.encode(keywords, convert_to_tensor=True)\n",
    "\n",
    "# Flatten category embeddings for FAISS indexing\n",
    "flat_embeddings = []\n",
    "category_indices = []\n",
    "for category, embeddings in category_embeddings.items():\n",
    "    for embedding in embeddings:\n",
    "        flat_embeddings.append(embedding.cpu().detach().numpy())\n",
    "        category_indices.append(category)\n",
    "\n",
    "flat_embeddings = np.vstack(flat_embeddings)\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = flat_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(flat_embeddings)\n",
    "\n",
    "# Save FAISS index and data for later use\n",
    "faiss.write_index(index, 'data/faiss_index.bin')\n",
    "np.save('data/category_indices.npy', category_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elbow_point_indices(data):\n",
    "    # Sort the data and keep track of the original indices\n",
    "    sorted_data_with_indices = sorted((val, idx) for idx, val in enumerate(data))\n",
    "    sorted_data = [val for val, idx in sorted_data_with_indices]\n",
    "    sorted_indices = [idx for val, idx in sorted_data_with_indices]\n",
    "    \n",
    "    # Calculate the differences between consecutive elements\n",
    "    differences = np.diff(sorted_data)\n",
    "    \n",
    "    # Find the index where the difference significantly increases\n",
    "    elbow_index = np.argmax(differences)\n",
    "    \n",
    "    # Find the elbow point value\n",
    "    elbow_point = sorted_data[elbow_index]\n",
    "    \n",
    "    # Find indices of elements to remove (smaller than or equal to the elbow point)\n",
    "    to_remove_indices = [idx for idx, val in enumerate(data) if val <= elbow_point]\n",
    "    return to_remove_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_database(text, model, index, category_indices,num_categories_to_search=20):\n",
    "    \"\"\"\n",
    "    Query the FAISS index with a text embedding and return the most relevant categories.\n",
    "    Avoid returning repetitive categories and apply a similarity threshold.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the text\n",
    "    text_embedding = model.encode([text], convert_to_tensor=True)\n",
    "    text_embedding = text_embedding.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    # Search the index for the most similar embeddings\n",
    "    distances, indices = index.search(text_embedding, num_categories_to_search)\n",
    "    to_remove = find_elbow_point_indices(distances[0])\n",
    "\n",
    "    # Filter out categories based on the threshold and avoid repetitions\n",
    "    seen_categories = set()\n",
    "    categories_by_vd = []\n",
    "    for idx in  indices[0]:\n",
    "        if idx in to_remove:\n",
    "            continue\n",
    "        category = category_indices[idx]\n",
    "        if category not in seen_categories:\n",
    "            categories_by_vd.append(category)\n",
    "            seen_categories.add(category)\n",
    "\n",
    "    \n",
    "\n",
    "    return categories_by_vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \" Regular Council \\nMEETING MINUTES \\nTuesday, April 9, 2024 \\nCouncil Chambers, 7:00pm \\nTown Hall, 474 South Fletcher Road, Gibsons, BC \\n \\n \\nPRESENT: \\nMayor Silas White  \\nCouncillor David Croal \\nCouncillor Annemarie De Andrade \\nCouncillor Stafford Lumley \\nCouncillor Christi Thompson \\nYouth Representative Cael Read \\n  \\nSTAFF: \\n  \\nEmanuel Machado, Chief Administrative Officer \\nRebecca Anderson, Corporate Officer \\nLorraine Coughlin, Director of Finance \\nTrevor Rutley, Director of Infrastructure Services \\nLesley-Anne Staats, Director of Planning via Zoom  \\nNoni Weitz, Manager of Financial Services \\nHeidi Siller, Executive Assistant (recorder) \\n \\nCALL TO ORDER \\nThe Mayor called the meeting to order at 7:00pm. \\n \\nAPPROVAL OF THE AGENDA \\n \\n \\nR2024-63 \\nRegular Council Agenda - April 9, 2024 Councillor De Andrade Councillor Lumley the Regular Business Agenda of April 9, 2024 be . \\nCARRIED \\n \\n \\nADOPTION OF MINUTES \\n \\n \\nR2024-64 \\nMinutes of the Regular Council Meeting - March 19, 2024 Councillor Croal Councillor De Andrade the minutes of the Regular Council meeting held March 19, 2024 be\",\n",
      "  \"categories\": [\n",
      "    \"youth_children\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"housing\",\n",
      "    \"healthy_built_environments__community_design/planning\",\n",
      "    \"youth_children\",\n",
      "    \"housing__permits\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \". \\nCARRIED \\n \\nRegular Council Meeting Minutes - Tuesday, April 9, 2024 \\nBYLAWS \\n \\n \\nR2024-65 \\nDevelopment Permit Delegation Authority Amendment Bylaw No.1054-04, \\n2024 Councillor Thompson Councillor Croal Development Permit Delegation Authority Amendment Bylaw No.1054-\\n04, 2024 be . \\nCARRIED \\n \\n \\nCOMMITTEE REPORTS \\n \\nCommittee-of-the-Whole Meeting - March 19, 2024 \\n \\nThe minutes of the Committee-of-the-Whole Meeting held March 19, 2024 were \\nreceived. \\n \\n \\n \\nR2024-66 \\n2024-2028 Preliminary General Services 5-Year Capital Plan Councillor Croal Councillor De Andrade the revised preliminary 5-year capital plan for general services be \\nintegrated into the 2024-2028 Financial Plan with the exception of the Dog \\nPark and Pickleball projects which are to be removed from the capital plan and \\nreferred to the 2025 Parks Master Plan for discussion; \\n \\nAND the proposed budget for the Healthy Harbours Project be , with the 2024 portion being funded by accumulated surplus. \\nCARRIED \\n \\n \\n \\nR2024-67 \\n2024 Annual Tax Rates Councillor Lumley Councillor Croal the 2024 annual tax rates be prepared authorizing an overall 8% tax \\nincrease (reflecting 3% for general operations and 5% for future policing \\ncosts). \\nCARRIED \\n \\n \\n \\n \\n \\nRegular Council Meeting Minutes - Tuesday, April 9, 2024 \\nR2024-68 \\n2024-2028 Financial Plan Bylaw and 2024 Annual Tax Rate Bylaw Councillor Lumley Councillor Croal\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"the 2024-2028 Financial Plan Bylaw and the 2024 Annual Tax Rate \\nBylaw be prepared for Council approval. \\nCARRIED \\n \\n \\nADMINISTRATION REPORTS \\n \\nBudget Presentation  \\n \\nThe budget presentation was received for information.  \\n \\n \\n \\nR2024-69 \\nParcel Tax Roll Review Panel \\u2013 Water/Sewer/Community Recreation \\nParcel Taxes Councillor De Andrade Councillor Thompson Council convene a Parcel Tax Roll Review Panel at 6:30 pm on \\nTuesday, May 7, 2024 in the Town\\u2019s Council chambers; \\n \\nAND\",\n",
      "  \"categories\": [\n",
      "    \"physical_activity\",\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"all members of Council be appointed to sit as members on the \\nParcel Tax Roll Review Panel. \\nCARRIED \\n \\n \\nCORRESPONDENCE \\n \\n \\nR2024-70 \\nCanada BC Housing Benefit Program - Memorandum of Understanding Councillor Croal Councillor Thompson\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"youth_children\",\n",
      "    \"harm_reduction\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"the Mayor and Corporate Officer be authorized to execute the Canada \\nBC Housing Benefit Program Memorandum of Understanding between the \\nSunshine Resource Centre, Town of Gibsons and Sunshine Coast Affordable \\nHousing Society. \\nCARRIED \\n \\n \\n \\nRegular Council Meeting Minutes - Tuesday, April 9, 2024 \\n \\nR2024-71 \\nSupport for Community Emergency Preparedness Fund (CEPF) Councillor De Andrade Councillor Croal\",\n",
      "  \"categories\": [\n",
      "    \"environmental_exposures__extreme_weather\",\n",
      "    \"injury_prevention\",\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"youth_children\",\n",
      "    \"mental_health\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"Council supports the Sunshine Coast Regional District applying for, \\nreceiving, and managing Community Emergency Preparedness Fund (CEPF) \\nEvacuation Route Planning grant funding on behalf of the Town of Gibsons. \\nCARRIED \\n \\n \\n \\nR2024-72 \\nAllocation of Community Event Fund: Councillor Croal Councillor De Andrade\",\n",
      "  \"categories\": [\n",
      "    \"environmental_exposures__extreme_weather\",\n",
      "    \"other__emergency_management\",\n",
      "    \"injury_prevention\",\n",
      "    \"other__geographically-oriented\",\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"other__emergency_management\",\n",
      "    \"mental_health\",\n",
      "    \"youth_children\",\n",
      "    \"environmental_exposures__extreme_weather\",\n",
      "    \"injury_prevention\",\n",
      "    \"environmental_exposures__air_quality_\",\n",
      "    \"housing__homelessness\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"the community event funding request in the amount of $5,000.00 for \\n2024 Oceanfest be ;  \\n  \\nAND the Town of Gibsons reinstates the Canada Day celebrations as \\nthey were prior to COVID. \\nCARRIED \\n \\n \\nNEXT MEETING \\n \\nThe next Regular meeting of Council to be held on Tuesday, April 23, 2024 at \\n7:00pm. \\n \\n \\nADJOURNMENT \\n \\nR2024-73 Councillor Croal Councillor Thompson the meeting be adjourned at 7:53pm. \\nCARRIED \\n \\n \\nRebecca Anderson, Corporate Officer \\nSilas White, Mayor\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"environmental_exposures__extreme_weather\",\n",
      "    \"housing\",\n",
      "    \"food\",\n",
      "    \"climate_change\",\n",
      "    \"children___youth\",\n",
      "    \"indigenous_relations\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the FAISS index and category indices\n",
    "index = faiss.read_index('data/faiss_index.bin')\n",
    "category_indices = np.load('data/category_indices.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "# Verify categories and update segments\n",
    "for segment in combined_segments:\n",
    "    suggested_categories = query_vector_database(segment['text'], model, index, category_indices)\n",
    "    segment[\"categories_by_vd\"] = suggested_categories\n",
    "\n",
    "# Print the updated categorized segments\n",
    "for segment in combined_segments:\n",
    "    print(json.dumps(segment, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
