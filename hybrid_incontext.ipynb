{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'gibsons',\n",
       " 'location type': 'municipality',\n",
       " 'meeting type': 'regular_council',\n",
       " 'data type': 'minutes',\n",
       " 'meeting date': Timestamp('2024-04-09 00:00:00'),\n",
       " 'transcript': 'Yes',\n",
       " 'comment': nan}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one file:\n",
    "pdf_folder = 'data/batch/'\n",
    "metting_name = \"gib_mcp_rgc_min__2024-04-09__01\"\n",
    "pdf_file = metting_name + \".pdf\"\n",
    "pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "# read the info from a xlsx file\n",
    "df = pd.read_excel(\"data/meetingmap.xlsx\")\n",
    "df = df.set_index('standard name')\n",
    "# get the info of the meeting\n",
    "meeting_info = df.loc[pdf_file]\n",
    "# return all the columns for the meeting\n",
    "meeting_info = meeting_info.to_dict()\n",
    "meeting_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# create a dictionary to store the text of each pdf and the metadata and if there is a txt with the same name\n",
    "contex = {}\n",
    "    \n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "contex['pdf'] = text\n",
    "# get the metadata\n",
    "metadata = fitz.open(pdf_path).metadata\n",
    "contex['metadata'] = metadata\n",
    "# check if there is a txt with the same name\n",
    "txt_path = os.path.join(pdf_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "if os.path.exists(txt_path):\n",
    "    with open(txt_path, 'r') as file:\n",
    "        contex['transcript'] = file.read()\n",
    "\n",
    "else:\n",
    "        contex['transcript'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pdf', 'metadata', 'transcript'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of themes:  56\n"
     ]
    }
   ],
   "source": [
    "# load the theme keywords from themekeywordmap.xlsx\n",
    "# convert it to a dictionary with the theme as key and different keywords as a list\n",
    "# it has two columns: theme and single phrase\n",
    "# combine all the phrases that have the same theme in  a list as follows\n",
    "# category_keywords = {\n",
    "#     \"theme 1\": [\"phrase 1\", \"phrase 2\", \"phrase 3\"],\n",
    "#     \"theme 2\": [\"phrase 4\", \"phrase 5\", \"phrase 6\", \"phrase 7\"]\n",
    "# }\n",
    "df = pd.read_excel(\"data/themekeywordmap.xlsx\")\n",
    "category_keywords = {}\n",
    "for theme, group in df.groupby('theme'):\n",
    "    category_keywords[theme] = group['phrase'].tolist()\n",
    "print(\"total number of themes: \", len(category_keywords.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Segment using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_patterns = [\n",
    "    r\"MOVED by\",\n",
    "    r\"SECONDED by\",\n",
    "    r\"WHEREAS\",\n",
    "    r\"THEREFORE BE IT RESOLVED THAT\",\n",
    "    r\"CARRIED UNANIMOUSLY\",\n",
    "    r\"REJECTED\",\n",
    "    r\"THAT\",\n",
    "    r\"APPROVED\",\n",
    "    r\"ADOPTED\",\n",
    "    r\"RESOLVED\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_document(document, patterns):\n",
    "    \"\"\"\n",
    "    Segment the document based on defined patterns.\n",
    "    \"\"\"\n",
    "    combined_pattern = '|'.join(patterns)\n",
    "    segments = re.split(combined_pattern, document, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Filter out empty segments and strip whitespace\n",
    "    segments = [seg.strip() for seg in segments if seg.strip()]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keywords(segment, category_keywords):\n",
    "    \"\"\"\n",
    "    Match segments against category keywords.\n",
    "    \"\"\"\n",
    "    matched_categories = []\n",
    "    for category, keywords in category_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', segment, re.IGNORECASE):\n",
    "                matched_categories.append(category)\n",
    "                break  # Break after the first match to avoid redundant checks\n",
    "    return matched_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_segments(segments, category_keywords):\n",
    "    \"\"\"\n",
    "    Combine nearby segments and filter them based on category keywords.\n",
    "    \"\"\"\n",
    "    combined_segments = []\n",
    "    current_segment = \"\"\n",
    "    current_categories = set()\n",
    "\n",
    "    for segment in segments:\n",
    "        matched_categories = match_keywords(segment, category_keywords)\n",
    "        if matched_categories:\n",
    "            if current_segment:\n",
    "                combined_segments.append({\n",
    "                    \"text\": current_segment,\n",
    "                    \"categories\": list(current_categories)\n",
    "                })\n",
    "                current_segment = segment\n",
    "                current_categories = set(matched_categories)\n",
    "            else:\n",
    "                current_segment = segment\n",
    "                current_categories.update(matched_categories)\n",
    "        else:\n",
    "            current_segment += \" \" + segment\n",
    "    \n",
    "    if current_segment:\n",
    "        combined_segments.append({\n",
    "            \"text\": current_segment,\n",
    "            \"categories\": list(current_categories)\n",
    "        })\n",
    "\n",
    "    return combined_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segment_document(contex['pdf'], split_patterns)\n",
    "combined_segments = combine_segments(segments, category_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total initial segments: 8\n"
     ]
    }
   ],
   "source": [
    "# initial assesment results\n",
    "print(\"Total initial segments:\", len(combined_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nlp = json.dumps(combined_segments, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_segments_v2(segments, category_keywords):\n",
    "    \"\"\"\n",
    "    Combine nearby segments and filter them based on category keywords.\n",
    "    \"\"\"\n",
    "    combined_segments = []\n",
    "    current_segment = \"\"\n",
    "    current_categories = set()\n",
    "    last_matched_categories = set()\n",
    "\n",
    "    for segment in segments:\n",
    "        matched_categories = match_keywords(segment, category_keywords)\n",
    "        if matched_categories:\n",
    "            # If current segment is not empty and the new segment has different categories,\n",
    "            # add the current segment to combined_segments and start a new one\n",
    "            if current_segment and matched_categories != last_matched_categories:\n",
    "                combined_segments.append({\n",
    "                    \"text\": current_segment,\n",
    "                    \"categories\": list(current_categories)\n",
    "                })\n",
    "                current_segment = segment\n",
    "                current_categories = set(matched_categories)\n",
    "            else:\n",
    "                current_segment += \" \" + segment\n",
    "                current_categories.update(matched_categories)\n",
    "            last_matched_categories = matched_categories\n",
    "        else:\n",
    "            current_segment += \" \" + segment\n",
    "    \n",
    "    # Append the last segment\n",
    "    if current_segment:\n",
    "        combined_segments.append({\n",
    "            \"text\": current_segment,\n",
    "            \"categories\": list(current_categories)\n",
    "        })\n",
    "\n",
    "    return combined_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Proposal_indicators = [\"Moved\", \"Seconded\", \"Motion\", \"Carried\", \"Proposal\", \"Passed\", \"Adopted\", \"Adoption\", \"Rejected\", \"Lost\", \"Moved\", \"approve\", \"Seconded\" , \"Adopt\", \"Resolution\", \"rejected\", \"Ordinance\", \"defeated\", \"discussed\", \"withdrawn\", \"tabled\", \"Amendment\", \"Amendment\", \"Recommendation\", \"granted\", \"Petition\", \"denied\", \"Vote\", \"result\"]\n",
    "# lower case it\n",
    "Proposal_indicators = [x.lower() for x in Proposal_indicators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_segments_v3(segments, category_keywords, Proposal_indicators):\n",
    "    combined_proposals = []\n",
    "    temp_segment = \"\"\n",
    "\n",
    "    def contains_proposal_indicators(text):\n",
    "            return any(indicator in text.lower() for indicator in Proposal_indicators)\n",
    "    def match_keywords(segment, category_keywords):\n",
    "        \"\"\"\n",
    "        Match segments against category keywords.\n",
    "        \"\"\"\n",
    "        matched_categories = []\n",
    "        for category, keywords in category_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if re.search(r'\\b' + re.escape(keyword) + r'\\b', segment, re.IGNORECASE):\n",
    "                    matched_categories.append(category)\n",
    "        return matched_categories\n",
    "  \n",
    "    \n",
    "    for seg in segments:\n",
    "        \"\"\"Splits/combine the segments such that it contains one proposals indicator.\"\"\"\n",
    "        for line in seg.split('\\n'):\n",
    "            temp_segment += line + \" \"\n",
    "            if contains_proposal_indicators(line):\n",
    "                categories = match_keywords(temp_segment, category_keywords)\n",
    "                combined_proposals.append({\n",
    "                    \"text\": temp_segment.strip(),\n",
    "                    \"categories\": list(set(categories))\n",
    "                })\n",
    "                temp_segment = \"\"\n",
    "                category_set = set()\n",
    "    if temp_segment.strip():\n",
    "        # append it to the last proposal\n",
    "        categories = match_keywords(temp_segment, category_keywords)\n",
    "        combined_proposals[-1] = {\n",
    "                    \"text\": combined_proposals[-1][\"text\"] + \" \" + temp_segment.strip(),\n",
    "                    \"categories\": list(set(categories+ combined_proposals[-1][\"categories\"]))\n",
    "                }\n",
    "    return combined_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_segments = combine_segments(segments, category_keywords)\n",
    "#combined_segments = combine_segments_v2(segments, category_keywords)\n",
    "combined_segments = combine_segments_v3(segments, category_keywords, Proposal_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post assesment results\n",
    "# if the len of the text is less than 50, add it to the previous segment\n",
    "for i in reversed(range(len(combined_segments))):\n",
    "    if len(combined_segments[i][\"text\"]) < 50:\n",
    "        combined_segments[i-1][\"text\"] = combined_segments[i-1][\"text\"] + \" \" + combined_segments[i][\"text\"]\n",
    "        # remove the current segment\n",
    "        del combined_segments[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: find category based on vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/pagand/projects/ragprop/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/local-scratch/localhome/pagand/projects/ragprop/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11080). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/local-scratch/localhome/pagand/projects/ragprop/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# Generate embeddings for each category based on keywords\n",
    "category_embeddings = {}\n",
    "for category, keywords in category_keywords.items():\n",
    "    category_embeddings[category] = model.encode(keywords, convert_to_tensor=True)\n",
    "\n",
    "# Flatten category embeddings for FAISS indexing\n",
    "flat_embeddings = []\n",
    "category_indices = []\n",
    "for category, embeddings in category_embeddings.items():\n",
    "    for embedding in embeddings:\n",
    "        flat_embeddings.append(embedding.cpu().detach().numpy())\n",
    "        category_indices.append(category)\n",
    "\n",
    "flat_embeddings = np.vstack(flat_embeddings)\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = flat_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(flat_embeddings)\n",
    "\n",
    "# Save FAISS index and data for later use\n",
    "faiss.write_index(index, 'data/faiss_index.bin')\n",
    "np.save('data/category_indices.npy', category_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elbow_point_indices(data):\n",
    "    # Sort the data and keep track of the original indices\n",
    "    sorted_data_with_indices = sorted((val, idx) for idx, val in enumerate(data))\n",
    "    sorted_data = [val for val, idx in sorted_data_with_indices]\n",
    "    sorted_indices = [idx for val, idx in sorted_data_with_indices]\n",
    "    \n",
    "    # Calculate the differences between consecutive elements\n",
    "    differences = np.diff(sorted_data)\n",
    "    \n",
    "    # Find the index where the difference significantly increases\n",
    "    elbow_index = np.argmax(differences)\n",
    "    \n",
    "    # Find the elbow point value\n",
    "    elbow_point = sorted_data[elbow_index]\n",
    "    \n",
    "    # Find indices of elements to remove (smaller than or equal to the elbow point)\n",
    "    to_remove_indices = [idx for idx, val in enumerate(data) if val <= elbow_point]\n",
    "    return to_remove_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_database(text, model, index, category_indices,num_categories_to_search=20):\n",
    "    \"\"\"\n",
    "    Query the FAISS index with a text embedding and return the most relevant categories.\n",
    "    Avoid returning repetitive categories and apply a similarity threshold.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the text\n",
    "    text_embedding = model.encode([text], convert_to_tensor=True)\n",
    "    text_embedding = text_embedding.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    # Search the index for the most similar embeddings\n",
    "    distances, indices = index.search(text_embedding, num_categories_to_search)\n",
    "    to_remove = find_elbow_point_indices(distances[0])\n",
    "\n",
    "    # Filter out categories based on the threshold and avoid repetitions\n",
    "    seen_categories = set()\n",
    "    categories_by_vd = []\n",
    "    for idx in  indices[0]:\n",
    "        if idx in to_remove:\n",
    "            continue\n",
    "        category = category_indices[idx]\n",
    "        if category not in seen_categories:\n",
    "            categories_by_vd.append(category)\n",
    "            seen_categories.add(category)\n",
    "\n",
    "    \n",
    "\n",
    "    return categories_by_vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Regular Council  MEETING MINUTES  Tuesday, April 9, 2024  Council Chambers, 7:00pm  Town Hall, 474 South Fletcher Road, Gibsons, BC      PRESENT:  Mayor Silas White   Councillor David Croal  Councillor Annemarie De Andrade  Councillor Stafford Lumley  Councillor Christi Thompson  Youth Representative Cael Read     STAFF:     Emanuel Machado, Chief Administrative Officer  Rebecca Anderson, Corporate Officer  Lorraine Coughlin, Director of Finance  Trevor Rutley, Director of Infrastructure Services  Lesley-Anne Staats, Director of Planning via Zoom   Noni Weitz, Manager of Financial Services  Heidi Siller, Executive Assistant (recorder)    CALL TO ORDER  The Mayor called the meeting to order at 7:00pm.    APPROVAL OF THE AGENDA      R2024-63  Regular Council Agenda - April 9, 2024 Councillor De Andrade Councillor Lumley the Regular Business Agenda of April 9, 2024 be .  CARRIED ADOPTION OF MINUTES\",\n",
      "  \"categories\": [\n",
      "    \"youth_children\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"housing\",\n",
      "    \"healthy_built_environments__community_design/planning\",\n",
      "    \"youth_children\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"R2024-64  Minutes of the Regular Council Meeting - March 19, 2024 Councillor Croal Councillor De Andrade the minutes of the Regular Council meeting held March 19, 2024 be .  CARRIED\",\n",
      "  \"categories\": [],\n",
      "  \"categories_by_vd\": [\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"housing\",\n",
      "    \"youth_children\",\n",
      "    \"healthy_built_environments__active_transportation\",\n",
      "    \"indigenous_relations__reconciliation\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"Regular Council Meeting Minutes - Tuesday, April 9, 2024  BYLAWS      R2024-65  Development Permit Delegation Authority Amendment Bylaw No.1054-04,\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"housing__permits\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"2024 Councillor Thompson Councillor Croal Development Permit Delegation Authority Amendment Bylaw No.1054- 04, 2024 be .  CARRIED\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"housing__permits\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"COMMITTEE REPORTS    Committee-of-the-Whole Meeting - March 19, 2024    The minutes of the Committee-of-the-Whole Meeting held March 19, 2024 were  received.        R2024-66  2024-2028 Preliminary General Services 5-Year Capital Plan Councillor Croal Councillor De Andrade the revised preliminary 5-year capital plan for general services be  integrated into the 2024-2028 Financial Plan with the exception of the Dog  Park and Pickleball projects which are to be removed from the capital plan and\",\n",
      "  \"categories\": [],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"healthy_built_environments__community_design/planning\",\n",
      "    \"other__emergency_management\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"referred to the 2025 Parks Master Plan for discussion;    AND the proposed budget for the Healthy Harbours Project be , with the 2024 portion being funded by accumulated surplus.  CARRIED\",\n",
      "  \"categories\": [],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"climate_change\",\n",
      "    \"poverty_affordability\",\n",
      "    \"healthy_built_environments__community_design/planning\",\n",
      "    \"healthy_built_environments__natural_environments/green_infrastructure\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"R2024-67  2024 Annual Tax Rates Councillor Lumley Councillor Croal the 2024 annual tax rates be prepared authorizing an overall 8% tax  increase (reflecting 3% for general operations and 5% for future policing  costs).  CARRIED\",\n",
      "  \"categories\": [],\n",
      "  \"categories_by_vd\": [\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"poverty_affordability\",\n",
      "    \"housing\",\n",
      "    \"youth_children\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"Regular Council Meeting Minutes - Tuesday, April 9, 2024  R2024-68  2024-2028 Financial Plan Bylaw and 2024 Annual Tax Rate Bylaw Councillor Lumley Councillor Croal the 2024-2028 Financial Plan Bylaw and the 2024 Annual Tax Rate  Bylaw be prepared for Council approval.  CARRIED\",\n",
      "  \"categories\": [],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"ADMINISTRATION REPORTS    Budget Presentation     The budget presentation was received for information.         R2024-69  Parcel Tax Roll Review Panel \\u2013 Water/Sewer/Community Recreation  Parcel Taxes Councillor De Andrade Councillor Thompson Council convene a Parcel Tax Roll Review Panel at 6:30 pm on  Tuesday, May 7, 2024 in the Town\\u2019s Council chambers;    AND all members of Council be appointed to sit as members on the  Parcel Tax Roll Review Panel.  CARRIED\",\n",
      "  \"categories\": [\n",
      "    \"housing\",\n",
      "    \"physical_activity\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"youth_children\",\n",
      "    \"environmental_exposures__liquid_waste/_wastewater/sewage\",\n",
      "    \"environmental_exposures__health_impact_assessments_/_human_health_risk_assessments_/_environmental_assessments\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"CORRESPONDENCE      R2024-70  Canada BC Housing Benefit Program - Memorandum of Understanding Councillor Croal Councillor Thompson the Mayor and Corporate Officer be authorized to execute the Canada  BC Housing Benefit Program Memorandum of Understanding between the  Sunshine Resource Centre, Town of Gibsons and Sunshine Coast Affordable  Housing Society.  CARRIED\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"youth_children\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"Regular Council Meeting Minutes - Tuesday, April 9, 2024    R2024-71  Support for Community Emergency Preparedness Fund (CEPF) Councillor De Andrade Councillor Croal Council supports the Sunshine Coast Regional District applying for,  receiving, and managing Community Emergency Preparedness Fund (CEPF)  Evacuation Route Planning grant funding on behalf of the Town of Gibsons.  CARRIED\",\n",
      "  \"categories\": [\n",
      "    \"housing\",\n",
      "    \"injury_prevention\",\n",
      "    \"other__emergency_management\",\n",
      "    \"other__geographically-oriented\",\n",
      "    \"environmental_exposures__extreme_weather\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"environmental_exposures__extreme_weather\",\n",
      "    \"injury_prevention\",\n",
      "    \"youth_children\",\n",
      "    \"other__emergency_management\",\n",
      "    \"mental_health\",\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"environmental_exposures__air_quality_\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"R2024-72  Allocation of Community Event Fund: Councillor Croal Councillor De Andrade the community event funding request in the amount of $5,000.00 for  2024 Oceanfest be ;      AND the Town of Gibsons reinstates the Canada Day celebrations as  they were prior to COVID.  CARRIED\",\n",
      "  \"categories\": [\n",
      "    \"housing\"\n",
      "  ],\n",
      "  \"categories_by_vd\": [\n",
      "    \"housing\",\n",
      "    \"environmental_exposures__extreme_weather\",\n",
      "    \"food\",\n",
      "    \"climate_change\",\n",
      "    \"children___youth\",\n",
      "    \"indigenous_relations\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"text\": \"NEXT MEETING    The next Regular meeting of Council to be held on Tuesday, April 23, 2024 at  7:00pm.      ADJOURNMENT    R2024-73 Councillor Croal Councillor Thompson the meeting be adjourned at 7:53pm.  CARRIED Rebecca Anderson, Corporate Officer  Silas White, Mayor\",\n",
      "  \"categories\": [],\n",
      "  \"categories_by_vd\": [\n",
      "    \"injury_prevention__youth_self-harm\",\n",
      "    \"housing\",\n",
      "    \"healthy_built_environments__community_design/planning\",\n",
      "    \"youth_children\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the FAISS index and category indices\n",
    "index = faiss.read_index('data/faiss_index.bin')\n",
    "category_indices = np.load('data/category_indices.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "# Verify categories and update segments\n",
    "for segment in combined_segments:\n",
    "    suggested_categories = query_vector_database(segment['text'], model, index, category_indices)\n",
    "    segment[\"categories_by_vd\"] = suggested_categories\n",
    "\n",
    "# Print the updated categorized segments\n",
    "for segment in combined_segments:\n",
    "    print(json.dumps(segment, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: lang-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the LANGCHAIN_API_KEY from the environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Index\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community import embeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the context['pdf'] and create vector store\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=50\n",
    ")\n",
    "def filter_none_values(metadata):\n",
    "    return {k: v for k, v in metadata.items() if v is not None}\n",
    "filtered_metadata = filter_none_values(contex['metadata'])\n",
    "\n",
    "text_splits = text_splitter.split_text(contex['pdf'])\n",
    "metadata_list = [filtered_metadata] * len(text_splits)\n",
    "\n",
    "# Add  text_splits to vectorDB with  nomic-embed-text-v1.5  and inference_mode=\"local\n",
    "vectorstore = Chroma.from_texts(\n",
    "        texts=text_splits,\n",
    "        metadatas=metadata_list,\n",
    "        # embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    "        embedding=embeddings.OllamaEmbeddings(model=\"nomic-embed-text:v1.5\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_count = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "You are an assitance that detect the number of unique proposals with a specific categoty (theme) in a suggested proposal of a council meeting note. \\n\n",
    "You are provided with suggested proposal and its category as user prompt. \\n\n",
    "The goal is to find count of unique proposal in the suggested proposal with the specific category. \\n\n",
    "Give a integer count of unique proposal as a JSON with single key 'count'. \\n\n",
    "\n",
    "example:\n",
    "proposal: ### Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\\n MOVED by Councillor Bligh\\n SECONDED by Councillor Zhou\\n  THAT the Minutes of the Court of Revision (Business Improvement Areas) meeting of\\n February 8, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n MATTERS ADOPTED ON CONSENT \n",
    "categories: [\"City Finance and Services\", \"Business Improvement Areas\"]\n",
    "output: \"count\": 2\n",
    "\n",
    "Let's think step by step. Here are the steps to solve the task:\n",
    "1. Validity check: A proposal should suggest some action or decision and it should have a unique decision. \n",
    "2. Proposal Count: See if the suggested proposal includes more than one proposal. calculate the count.\n",
    "5. Write: Only return the count as integer in a JSON format with a single key 'count'.\n",
    "\n",
    "RULES:\n",
    "- your output MUST HAVE the exact JSON format.\n",
    "- Your answer must not include any speculation or inference. Do not assume or change dates and times. Only provide information that is explicitly stated in the context.\n",
    "- An answer is considered grounded if **all** information in **every** sentence in the answer is **explicitly** mentioned in the source context, **no** extra information is added and **no** inferred information is added.\n",
    "\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Category:\\n {category} \\n\\n\n",
    "    Suggested proposal:\\n {proposal} \\n\\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"category\", \"proposal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 0}\n"
     ]
    }
   ],
   "source": [
    "num = 12\n",
    "proposal = combined_segments[num][\"text\"]\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "retrieval_grader = prompt_count | llm | JsonOutputParser()\n",
    "category = combined_segments[num][\"categories_by_vd\"]\n",
    "print(retrieval_grader.invoke({\"category\": category, \"proposal\": proposal}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_boundry = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "You are an assitance that detect boundry of a suggested proposal from chunk of a council meeting note. \\n\n",
    "You are provided with chunk of meeting note and suggested proposal as user prompt. \\n\n",
    "The goal is to find few words from beggining and end of the proposal in the originam context. \\n\n",
    "Give a integer count of unique proposal as a JSON with keys 'start', 'end' as string. \\n\n",
    "\n",
    "RULE: \n",
    "1- Do not use speculations or inferences. Only provide information that is explicitly stated in the context.\n",
    "2- The boundry is part of context that starts from 'start' and end with 'end'.\n",
    "2- The boundary should be selected such that anything outside that in the context, does not have any related information about the proposal (including the result, mover, ...).\n",
    "3- Both of start and end MUST have atleast 10 and atmost 20 words. \n",
    "4- Provide JSON with  key 'start', 'end'  and no premable or explanation.\n",
    "\n",
    "Example:\n",
    "context: Minutes of the Council meeting of February 6, 2024, be approved.\\n CARRIED UNANIMOUSLY \\n Council Meeting\\n Minutes, February 27, 2024 3\\n 3. Council (City Finance and Services) \\n MOVED by Councillor Dominato\\n SECONDED by Councillor Carr\\n THAT the Minutes of the Council meeting following the Standing Committee on City\\n Finance and Services meeting of February 7, 2024, be approved.\\n CARRIED UNANIMOUSLY\\n 4. Court of Revision (Business Improvement Areas) - February 8, 2024\n",
    "proposal: the Minutes of the Council meeting following the Standing Committee on City Finance \n",
    "\n",
    "AI output:\n",
    "\"start\": \"3. Council (City Finance and Services) MOVED by Councillor Dominato SECONDED by Councillor Carr\"\n",
    "\"end\": \"and Services meeting of February 7, 2024, be approved. CARRIED UNANIMOUSLY\"\n",
    "\n",
    "\n",
    "Important: 'start' and 'end' should be atleast ten words and not more than twenty words.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Chunk of meeting note as context:\\n {document} \\n\\n\n",
    "    Suggested proposal:\\n {proposal} \\n\\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"document\", \"proposal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 'THAT the 2024-2028 Financial Plan Bylaw and the 2024 Annual Tax Rate Bylaw be prepared for Council approval.', 'end': 'Councillor De Andrade the minutes of the Regular Council meeting held March 19, 2024 be . CARRIED'}\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "proposal = combined_segments[num][\"text\"]\n",
    "\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "retrieval_grader = prompt_boundry | llm | JsonOutputParser()\n",
    "txt_chunk = retriever.invoke(proposal)\n",
    "boundry = retrieval_grader.invoke({\"document\": txt_chunk[num], \"proposal\": proposal})\n",
    "print(boundry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def find_closest_match(original_string, substring):\n",
    "    # Initialize variables\n",
    "    closest_match_index = -1\n",
    "    highest_similarity = 0\n",
    "    substring_length = len(substring)\n",
    "    \n",
    "    # Define a function to calculate similarity ratio\n",
    "    def similarity(s1, s2):\n",
    "        return difflib.SequenceMatcher(None, s1, s2).ratio()\n",
    "    \n",
    "    # Compare the substring against all possible substrings of the same length in the original string\n",
    "    for i in range(len(original_string) - substring_length + 1):\n",
    "        current_substring = original_string[i:i + substring_length]\n",
    "        current_similarity = similarity(current_substring, substring)\n",
    "        if current_similarity > highest_similarity:\n",
    "            highest_similarity = current_similarity\n",
    "            closest_match_index = i\n",
    "    \n",
    "    return closest_match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THAT the 2024-2028 Financial Plan Bylaw and the 2024 Annual Tax Rate  Bylaw be prepared for Council approval.  CARRIED      ADMINISTRATION REPORTS    Budget Presentation     The budget presentation was received for information.         R2024-69  Parcel Tax Roll Review Panel â€“ Water/Sewer/Community Recreation  Parcel Taxes  MOVED by Councillor De Andrade   SECONDED by Councillor Thompson    THAT Council convene a Parcel Tax R'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = boundry[\"start\"]\n",
    "end = boundry[\"end\"]\n",
    "start_index = find_closest_match(txt_chunk[num].page_content.replace('\\n', ' ').strip(), start)\n",
    "end_index = find_closest_match(txt_chunk[num].page_content.replace('\\n', ' ').strip(), end)\n",
    "proposal = txt_chunk[num].page_content.replace('\\n', ' ').strip()[start_index:end_index+len(end)]\n",
    "proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Councillor De Andrade the minutes of the Regular Council meeting held March 19, 2024 be . CARRIED'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
